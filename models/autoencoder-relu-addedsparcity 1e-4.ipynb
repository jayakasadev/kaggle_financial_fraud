{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 23 23:15:20 2018       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 390.48                 Driver Version: 390.48                    |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 1080    Off  | 00000000:26:00.0  On |                  N/A |\r\n",
      "| 21%   49C    P2    46W / 200W |   1093MiB /  8118MiB |      2%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      1214      G   /usr/lib/xorg/Xorg                           389MiB |\r\n",
      "|    0      2077      G   compiz                                       190MiB |\r\n",
      "|    0      2376      G   ...-token=DF74AF64EAA3938418CFC9F567B83A3C    87MiB |\r\n",
      "|    0     14165      C   /opt/anaconda/bin/python                     203MiB |\r\n",
      "|    0     15053      C   /opt/anaconda/bin/python                     203MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  6362620  samples\n",
      "(6362620, 12)\n",
      "   step    amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n",
      "0     1   9839.64      170136.00       160296.36             0.0   \n",
      "1     1   1864.28       21249.00        19384.72             0.0   \n",
      "2     1    181.00         181.00            0.00             0.0   \n",
      "3     1    181.00         181.00            0.00         21182.0   \n",
      "4     1  11668.14       41554.00        29885.86             0.0   \n",
      "5     1   7817.71       53860.00        46042.29             0.0   \n",
      "6     1   7107.77      183195.00       176087.23             0.0   \n",
      "7     1   7861.64      176087.23       168225.59             0.0   \n",
      "8     1   4024.36        2671.00            0.00             0.0   \n",
      "9     1   5337.77       41720.00        36382.23         41898.0   \n",
      "\n",
      "   newbalanceDest  isFraud  CASH_IN  CASH_OUT  DEBIT  PAYMENT  TRANSFER  \n",
      "0            0.00        0        0         0      0        1         0  \n",
      "1            0.00        0        0         0      0        1         0  \n",
      "2            0.00        1        0         0      0        0         1  \n",
      "3            0.00        1        0         1      0        0         0  \n",
      "4            0.00        0        0         0      0        1         0  \n",
      "5            0.00        0        0         0      0        1         0  \n",
      "6            0.00        0        0         0      0        1         0  \n",
      "7            0.00        0        0         0      0        1         0  \n",
      "8            0.00        0        0         0      0        1         0  \n",
      "9        40348.79        0        0         0      1        0         0  \n",
      "               step        amount  oldbalanceOrg  newbalanceOrig  \\\n",
      "count  6.362620e+06  6.362620e+06   6.362620e+06    6.362620e+06   \n",
      "mean   2.433972e+02  1.798619e+05   8.338831e+05    8.551137e+05   \n",
      "std    1.423320e+02  6.038582e+05   2.888243e+06    2.924049e+06   \n",
      "min    1.000000e+00  0.000000e+00   0.000000e+00    0.000000e+00   \n",
      "25%    1.560000e+02  1.338957e+04   0.000000e+00    0.000000e+00   \n",
      "50%    2.390000e+02  7.487194e+04   1.420800e+04    0.000000e+00   \n",
      "75%    3.350000e+02  2.087215e+05   1.073152e+05    1.442584e+05   \n",
      "max    7.430000e+02  9.244552e+07   5.958504e+07    4.958504e+07   \n",
      "\n",
      "       oldbalanceDest  newbalanceDest       isFraud       CASH_IN  \\\n",
      "count    6.362620e+06    6.362620e+06  6.362620e+06  6.362620e+06   \n",
      "mean     1.100702e+06    1.224996e+06  1.290820e-03  2.199226e-01   \n",
      "std      3.399180e+06    3.674129e+06  3.590480e-02  4.141940e-01   \n",
      "min      0.000000e+00    0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%      0.000000e+00    0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "50%      1.327057e+05    2.146614e+05  0.000000e+00  0.000000e+00   \n",
      "75%      9.430367e+05    1.111909e+06  0.000000e+00  0.000000e+00   \n",
      "max      3.560159e+08    3.561793e+08  1.000000e+00  1.000000e+00   \n",
      "\n",
      "           CASH_OUT         DEBIT       PAYMENT      TRANSFER  \n",
      "count  6.362620e+06  6.362620e+06  6.362620e+06  6.362620e+06  \n",
      "mean   3.516633e-01  6.511783e-03  3.381461e-01  8.375622e-02  \n",
      "std    4.774895e-01  8.043246e-02  4.730786e-01  2.770219e-01  \n",
      "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
      "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
      "50%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
      "75%    1.000000e+00  0.000000e+00  1.000000e+00  0.000000e+00  \n",
      "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  \n"
     ]
    }
   ],
   "source": [
    "# importing data science libraries\n",
    "import pandas as pd\n",
    "\n",
    "fraud_dataset = pd.read_csv('../data/nonames.csv')\n",
    "print(\"There are \", len(fraud_dataset), \" samples\")\n",
    "print(fraud_dataset.shape)\n",
    "print(fraud_dataset.head(10))\n",
    "print(fraud_dataset.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (5090096, 12)\n",
      "X_train:  (5090096, 11)\n",
      "X_train:  (4072076, 11)\n",
      "X_val:  (1018020, 11)\n",
      "X_test:  (1272524, 12)\n",
      "X_test:  (1272524, 11)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = train_test_split(fraud_dataset, test_size=0.2, random_state=RANDOM_SEED)\n",
    "print(\"X_train: \", X_train.shape)\n",
    "# y_train = X_train[\"isFraud\"].copy(deep=True)\n",
    "X_train.pop(\"isFraud\")\n",
    "print(\"X_train: \", X_train.shape)\n",
    "X_train, X_val = train_test_split(X_train, test_size=0.2, random_state=RANDOM_SEED)\n",
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"X_val: \", X_val.shape)\n",
    "print(\"X_test: \", X_test.shape)\n",
    "y_test = X_test[\"isFraud\"].copy(deep=True)\n",
    "X_test.pop(\"isFraud\")\n",
    "print(\"X_test: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1]\n",
    "\n",
    "hidden_layer = [10, 8, 4]\n",
    "input_layer = Input(shape=(input_shape,))\n",
    "encoder1 = Dense(hidden_layer[0], activation=\"relu\", activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "encoder2 = Dense(hidden_layer[1], activation=\"relu\", activity_regularizer=regularizers.l1(10e-5))(encoder1)\n",
    "encoder3 = Dense(hidden_layer[2], activation=\"relu\", activity_regularizer=regularizers.l1(10e-5))(encoder2)\n",
    "decoder1 = Dense(hidden_layer[2], activation=\"relu\", activity_regularizer=regularizers.l1(10e-5))(encoder3)\n",
    "decoder2 = Dense(hidden_layer[1], activation=\"relu\", activity_regularizer=regularizers.l1(10e-5))(decoder1)\n",
    "decoder3 = Dense(input_shape, activation=\"relu\", activity_regularizer=regularizers.l1(10e-5))(decoder2)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 11)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                120       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 11)                99        \n",
      "=================================================================\n",
      "Total params: 403\n",
      "Trainable params: 403\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4072076 samples, validate on 1018020 samples\n",
      "Epoch 1/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 2107387974462.8569 - acc: 0.5313 - val_loss: 2059654536540.5354 - val_acc: 0.5516\n",
      "Epoch 2/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 2020280711119.9331 - acc: 0.5884 - val_loss: 2025696488522.8574 - val_acc: 0.7019\n",
      "Epoch 3/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1994880766803.1514 - acc: 0.6985 - val_loss: 2025506524425.5708 - val_acc: 0.7076\n",
      "Epoch 4/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1994825913717.5107 - acc: 0.7080 - val_loss: 2025558162303.9927 - val_acc: 0.7033\n",
      "Epoch 5/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1994819221777.3303 - acc: 0.7072 - val_loss: 2025569167288.1804 - val_acc: 0.7114\n",
      "Epoch 6/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1994630057166.0425 - acc: 0.7062 - val_loss: 2025201294089.3799 - val_acc: 0.6997\n",
      "Epoch 7/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992822092650.8821 - acc: 0.7384 - val_loss: 2023590426858.5295 - val_acc: 0.7405\n",
      "Epoch 8/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992701718555.1948 - acc: 0.7382 - val_loss: 2023534209209.6843 - val_acc: 0.7446\n",
      "Epoch 9/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992585492436.0854 - acc: 0.7517 - val_loss: 2023528829780.5789 - val_acc: 0.7624\n",
      "Epoch 10/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992596992370.4475 - acc: 0.7584 - val_loss: 2023524722232.1780 - val_acc: 0.7642\n",
      "Epoch 11/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992592281762.7466 - acc: 0.7640 - val_loss: 2023531697309.2180 - val_acc: 0.7702\n",
      "Epoch 12/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992593904095.9756 - acc: 0.7643 - val_loss: 2023524359925.6448 - val_acc: 0.7601\n",
      "Epoch 13/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992599406155.0742 - acc: 0.7651 - val_loss: 2023567150580.5432 - val_acc: 0.7737\n",
      "Epoch 14/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992600459432.3894 - acc: 0.7599 - val_loss: 2023522613336.7180 - val_acc: 0.7513\n",
      "Epoch 15/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992596902892.4309 - acc: 0.7533 - val_loss: 2023523530429.9995 - val_acc: 0.7434\n",
      "Epoch 16/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992578674198.0303 - acc: 0.7524 - val_loss: 2023527517967.4753 - val_acc: 0.7315\n",
      "Epoch 17/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992649619731.9375 - acc: 0.7540 - val_loss: 2023520334139.8445 - val_acc: 0.7538\n",
      "Epoch 18/200\n",
      "4072076/4072076 [==============================] - 26s 6us/step - loss: 1992624606071.4495 - acc: 0.7454 - val_loss: 2023519960181.2649 - val_acc: 0.7489\n",
      "Epoch 19/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992579028336.8916 - acc: 0.7576 - val_loss: 2023519574954.3196 - val_acc: 0.7675\n",
      "Epoch 20/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992589710232.6936 - acc: 0.7507 - val_loss: 2023519339275.2705 - val_acc: 0.7545\n",
      "Epoch 21/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992581522748.8638 - acc: 0.7488 - val_loss: 2023534172387.9314 - val_acc: 0.7634\n",
      "Epoch 22/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992585066857.8796 - acc: 0.7500 - val_loss: 2023550879879.6321 - val_acc: 0.7271\n",
      "Epoch 23/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992587120459.7673 - acc: 0.7521 - val_loss: 2023551185007.4512 - val_acc: 0.7752\n",
      "Epoch 24/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992606104214.8374 - acc: 0.7537 - val_loss: 2023519510127.7427 - val_acc: 0.7697\n",
      "Epoch 25/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992587443573.1909 - acc: 0.7517 - val_loss: 2023519233826.1846 - val_acc: 0.7444\n",
      "Epoch 26/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992595608245.7036 - acc: 0.7520 - val_loss: 2023519132047.8149 - val_acc: 0.7723\n",
      "Epoch 27/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992585035808.1719 - acc: 0.7534 - val_loss: 2023519810379.7273 - val_acc: 0.7439\n",
      "Epoch 28/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992598489400.7327 - acc: 0.7498 - val_loss: 2023519258031.5398 - val_acc: 0.7638\n",
      "Epoch 29/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992582686864.4780 - acc: 0.7543 - val_loss: 2023570053098.7961 - val_acc: 0.7745\n",
      "Epoch 30/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992589620556.7849 - acc: 0.7498 - val_loss: 2023519214964.0330 - val_acc: 0.7445\n",
      "Epoch 31/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992585059240.1377 - acc: 0.7514 - val_loss: 2023519217925.3262 - val_acc: 0.7479\n",
      "Epoch 32/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992584401952.3337 - acc: 0.7531 - val_loss: 2023519038702.6936 - val_acc: 0.7464\n",
      "Epoch 33/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992586043104.2151 - acc: 0.7503 - val_loss: 2023519465649.1143 - val_acc: 0.7480\n",
      "Epoch 34/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992579347366.3655 - acc: 0.7556 - val_loss: 2023519551525.3379 - val_acc: 0.7290\n",
      "Epoch 35/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992625778867.9106 - acc: 0.7339 - val_loss: 2023519207303.2952 - val_acc: 0.7687\n",
      "Epoch 36/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992580495837.0645 - acc: 0.7516 - val_loss: 2023520616760.5452 - val_acc: 0.7285\n",
      "Epoch 37/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992590460843.6936 - acc: 0.7491 - val_loss: 2023519043465.2261 - val_acc: 0.7709\n",
      "Epoch 38/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992587143986.3660 - acc: 0.7409 - val_loss: 2023518895916.8469 - val_acc: 0.7295\n",
      "Epoch 39/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992584625173.5691 - acc: 0.7471 - val_loss: 2023538153118.2944 - val_acc: 0.7284\n",
      "Epoch 40/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992586212116.2161 - acc: 0.7571 - val_loss: 2023519195974.4160 - val_acc: 0.7532\n",
      "Epoch 41/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992577431856.5530 - acc: 0.7456 - val_loss: 2023579415275.8071 - val_acc: 0.7744\n",
      "Epoch 42/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992590221916.7725 - acc: 0.7641 - val_loss: 2023530297816.0769 - val_acc: 0.7743\n",
      "Epoch 43/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992582085659.5076 - acc: 0.7537 - val_loss: 2023557411051.0527 - val_acc: 0.7726\n",
      "Epoch 44/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992581493175.2979 - acc: 0.7584 - val_loss: 2023519919823.9849 - val_acc: 0.7699\n",
      "Epoch 45/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992586856909.6665 - acc: 0.7376 - val_loss: 2023518747013.9976 - val_acc: 0.7432\n",
      "Epoch 46/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992598982239.1855 - acc: 0.7389 - val_loss: 2023519962312.1086 - val_acc: 0.7286\n",
      "Epoch 47/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992577919154.9995 - acc: 0.7413 - val_loss: 2023520883217.7336 - val_acc: 0.7289\n",
      "Epoch 48/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992581110171.2642 - acc: 0.7405 - val_loss: 2023519823968.2019 - val_acc: 0.7600\n",
      "Epoch 49/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992601427407.3733 - acc: 0.7467 - val_loss: 2023518755834.7896 - val_acc: 0.7743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992586996152.3984 - acc: 0.7578 - val_loss: 2023522158440.8372 - val_acc: 0.7296\n",
      "Epoch 51/200\n",
      "4072076/4072076 [==============================] - 24s 6us/step - loss: 1992585647435.6179 - acc: 0.7422 - val_loss: 2023527376630.0872 - val_acc: 0.7752\n",
      "Epoch 52/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992593123341.4888 - acc: 0.7424 - val_loss: 2023548385987.6929 - val_acc: 0.7313\n",
      "Epoch 53/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992597790747.8667 - acc: 0.7362 - val_loss: 2023519105528.7878 - val_acc: 0.7336\n",
      "Epoch 54/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992664574413.3044 - acc: 0.7452 - val_loss: 2023521736683.1179 - val_acc: 0.7622\n",
      "Epoch 55/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992572269606.2163 - acc: 0.7602 - val_loss: 2023527743319.3352 - val_acc: 0.7751\n",
      "Epoch 56/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992589612182.4316 - acc: 0.7625 - val_loss: 2023528879388.6826 - val_acc: 0.7357\n",
      "Epoch 57/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992592315503.2427 - acc: 0.7620 - val_loss: 2023518487584.0876 - val_acc: 0.7539\n",
      "Epoch 58/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992592998059.0164 - acc: 0.7551 - val_loss: 2023518283250.9736 - val_acc: 0.7656\n",
      "Epoch 59/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992583237708.9978 - acc: 0.7543 - val_loss: 2023518140465.1270 - val_acc: 0.7647\n",
      "Epoch 60/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992583786658.1592 - acc: 0.7396 - val_loss: 2023518107118.3875 - val_acc: 0.7291\n",
      "Epoch 61/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992578687711.8420 - acc: 0.7415 - val_loss: 2023530474904.0029 - val_acc: 0.7747\n",
      "Epoch 62/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992580499398.8604 - acc: 0.7396 - val_loss: 2023526949869.0696 - val_acc: 0.7278\n",
      "Epoch 63/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992586608107.2080 - acc: 0.7383 - val_loss: 2023518026197.8235 - val_acc: 0.7446\n",
      "Epoch 64/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992588332206.4177 - acc: 0.7607 - val_loss: 2023528515676.1780 - val_acc: 0.7544\n",
      "Epoch 65/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992573529023.3010 - acc: 0.7402 - val_loss: 2023518059993.9075 - val_acc: 0.7314\n",
      "Epoch 66/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992574097465.5178 - acc: 0.7402 - val_loss: 2023517988343.4802 - val_acc: 0.7293\n",
      "Epoch 67/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992595063747.4998 - acc: 0.7384 - val_loss: 2023520401814.4133 - val_acc: 0.7364\n",
      "Epoch 68/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992575647129.4343 - acc: 0.7406 - val_loss: 2023540339477.3298 - val_acc: 0.7279\n",
      "Epoch 69/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992581964575.7029 - acc: 0.7411 - val_loss: 2023517971735.7739 - val_acc: 0.7324\n",
      "Epoch 70/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992579103665.9631 - acc: 0.7462 - val_loss: 2023518111046.6074 - val_acc: 0.7747\n",
      "Epoch 71/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992596861656.2495 - acc: 0.7467 - val_loss: 2023517916308.0847 - val_acc: 0.7530\n",
      "Epoch 72/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992574115103.0637 - acc: 0.7468 - val_loss: 2023518739295.3220 - val_acc: 0.7478\n",
      "Epoch 73/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992582100238.7424 - acc: 0.7452 - val_loss: 2023556838075.5251 - val_acc: 0.7545\n",
      "Epoch 74/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992582488977.9060 - acc: 0.7477 - val_loss: 2023518025681.5283 - val_acc: 0.7371\n",
      "Epoch 75/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992576616668.5623 - acc: 0.7474 - val_loss: 2023519018116.5542 - val_acc: 0.7743\n",
      "Epoch 76/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992574265816.8921 - acc: 0.7491 - val_loss: 2023546706720.5552 - val_acc: 0.7278\n",
      "Epoch 77/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992581535709.5566 - acc: 0.7469 - val_loss: 2023518569857.8330 - val_acc: 0.7718\n",
      "Epoch 78/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992575586188.0144 - acc: 0.7501 - val_loss: 2023518918642.8433 - val_acc: 0.7701\n",
      "Epoch 79/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992578888023.2004 - acc: 0.7445 - val_loss: 2023517900793.4819 - val_acc: 0.7527\n",
      "Epoch 80/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992595986090.6443 - acc: 0.7456 - val_loss: 2023517900277.1868 - val_acc: 0.7602\n",
      "Epoch 81/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992591122892.6184 - acc: 0.7440 - val_loss: 2023518027356.5908 - val_acc: 0.7284\n",
      "Epoch 82/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992595690975.0552 - acc: 0.7420 - val_loss: 2023518157074.1208 - val_acc: 0.7395\n",
      "Epoch 83/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992576643952.0803 - acc: 0.7540 - val_loss: 2023517919589.9705 - val_acc: 0.7420\n",
      "Epoch 84/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992575031160.7280 - acc: 0.7431 - val_loss: 2023517869247.9812 - val_acc: 0.7326\n",
      "Epoch 85/200\n",
      "4072076/4072076 [==============================] - 25s 6us/step - loss: 1992586961033.9980 - acc: 0.7405 - val_loss: 2023517906909.1970 - val_acc: 0.7360\n",
      "Epoch 86/200\n",
      "4072076/4072076 [==============================] - 26s 6us/step - loss: 1992575493597.5461 - acc: 0.7435 - val_loss: 2023517836803.7922 - val_acc: 0.7356\n",
      "Epoch 87/200\n",
      "4072076/4072076 [==============================] - 26s 6us/step - loss: 1992577794919.0879 - acc: 0.7435 - val_loss: 2023519972478.3577 - val_acc: 0.7740\n",
      "Epoch 88/200\n",
      "4072076/4072076 [==============================] - 27s 7us/step - loss: 1992586289237.0647 - acc: 0.7425 - val_loss: 2023529649762.7468 - val_acc: 0.7277\n",
      "Epoch 89/200\n",
      "4072076/4072076 [==============================] - 29s 7us/step - loss: 1992587201400.8818 - acc: 0.7363 - val_loss: 2023517825536.7141 - val_acc: 0.7311\n",
      "Epoch 90/200\n",
      "4072076/4072076 [==============================] - 29s 7us/step - loss: 1992575489413.2344 - acc: 0.7405 - val_loss: 2023518044996.8875 - val_acc: 0.7285\n",
      "Epoch 91/200\n",
      "4072076/4072076 [==============================] - 29s 7us/step - loss: 1992584897858.6255 - acc: 0.7407 - val_loss: 2023518323485.9399 - val_acc: 0.7526\n",
      "Epoch 92/200\n",
      "4072076/4072076 [==============================] - 29s 7us/step - loss: 1992573735349.3101 - acc: 0.7441 - val_loss: 2023522138677.4219 - val_acc: 0.7744\n",
      "Epoch 93/200\n",
      "4072076/4072076 [==============================] - 29s 7us/step - loss: 1992578916968.1992 - acc: 0.7453 - val_loss: 2023517980301.6375 - val_acc: 0.7295\n",
      "Epoch 94/200\n",
      "4072076/4072076 [==============================] - 29s 7us/step - loss: 1992579816737.7676 - acc: 0.7406 - val_loss: 2023518119674.2715 - val_acc: 0.7338\n",
      "Epoch 95/200\n",
      "4072076/4072076 [==============================] - 26s 6us/step - loss: 1992574348291.8293 - acc: 0.7455 - val_loss: 2023517906780.4448 - val_acc: 0.7300\n",
      "Epoch 96/200\n",
      "4072076/4072076 [==============================] - 27s 7us/step - loss: 1992578833051.3682 - acc: 0.7423 - val_loss: 2023517800238.2549 - val_acc: 0.7534\n",
      "Epoch 97/200\n",
      "4072076/4072076 [==============================] - 27s 7us/step - loss: 1992586090893.5522 - acc: 0.7388 - val_loss: 2023517970835.7981 - val_acc: 0.7365\n",
      "Epoch 98/200\n",
      "4072076/4072076 [==============================] - 28s 7us/step - loss: 1992582410681.6155 - acc: 0.7393 - val_loss: 2023517745002.4067 - val_acc: 0.7306\n",
      "Epoch 99/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4072076/4072076 [==============================] - 29s 7us/step - loss: 1992577235928.0415 - acc: 0.7383 - val_loss: 2023518315830.3523 - val_acc: 0.7293\n",
      "Epoch 100/200\n",
      "4072076/4072076 [==============================] - 29s 7us/step - loss: 1992578980294.8789 - acc: 0.7416 - val_loss: 2023519094131.6702 - val_acc: 0.7287\n",
      "Epoch 101/200\n",
      "4072076/4072076 [==============================] - 29s 7us/step - loss: 1992576316913.0081 - acc: 0.7398 - val_loss: 2023517691441.6201 - val_acc: 0.7302\n",
      "Epoch 102/200\n",
      "2150000/4072076 [==============>...............] - ETA: 12s - loss: 2026418770030.4968 - acc: 0.7496"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6c5f936f693c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     callbacks=[checkpointer, tensorboard])\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nb_epoch = 200\n",
    "batch_size = 1000\n",
    "# using mean squared error\n",
    "autoencoder.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath=\"../saved/basicAE4.h5\",\n",
    "                               verbose=0,\n",
    "                               save_best_only=True)\n",
    "tensorboard = TensorBoard(log_dir='./logs',)\n",
    "history = autoencoder.fit(X_train, X_train,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(X_val, X_val),\n",
    "                    verbose=1,\n",
    "                    callbacks=[checkpointer, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing visualization tools\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "\n",
    "autoencoder = load_model('../saved/basicAE4.h5')\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "predictions = autoencoder.predict(X_test)\n",
    "# calculate my own MSE\n",
    "mse = np.mean(np.power(X_test - predictions, 2), axis=1)\n",
    "error_df = pd.DataFrame({'reconstruction_error': mse})\n",
    "error_df.describe()\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions[0][:])\n",
    "X_test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
