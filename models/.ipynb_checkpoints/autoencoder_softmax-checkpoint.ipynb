{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 23 21:18:17 2018       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 390.48                 Driver Version: 390.48                    |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 1080    Off  | 00000000:26:00.0  On |                  N/A |\r\n",
      "| 22%   49C    P2    46W / 200W |    861MiB /  8118MiB |     19%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      1214      G   /usr/lib/xorg/Xorg                           388MiB |\r\n",
      "|    0      2077      G   compiz                                       194MiB |\r\n",
      "|    0      2376      G   ...-token=DF74AF64EAA3938418CFC9F567B83A3C    63MiB |\r\n",
      "|    0     13425      C   /opt/anaconda/bin/python                     203MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  6362620  samples\n",
      "(6362620, 12)\n",
      "   step    amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n",
      "0     1   9839.64      170136.00       160296.36             0.0   \n",
      "1     1   1864.28       21249.00        19384.72             0.0   \n",
      "2     1    181.00         181.00            0.00             0.0   \n",
      "3     1    181.00         181.00            0.00         21182.0   \n",
      "4     1  11668.14       41554.00        29885.86             0.0   \n",
      "5     1   7817.71       53860.00        46042.29             0.0   \n",
      "6     1   7107.77      183195.00       176087.23             0.0   \n",
      "7     1   7861.64      176087.23       168225.59             0.0   \n",
      "8     1   4024.36        2671.00            0.00             0.0   \n",
      "9     1   5337.77       41720.00        36382.23         41898.0   \n",
      "\n",
      "   newbalanceDest  isFraud  CASH_IN  CASH_OUT  DEBIT  PAYMENT  TRANSFER  \n",
      "0            0.00        0        0         0      0        1         0  \n",
      "1            0.00        0        0         0      0        1         0  \n",
      "2            0.00        1        0         0      0        0         1  \n",
      "3            0.00        1        0         1      0        0         0  \n",
      "4            0.00        0        0         0      0        1         0  \n",
      "5            0.00        0        0         0      0        1         0  \n",
      "6            0.00        0        0         0      0        1         0  \n",
      "7            0.00        0        0         0      0        1         0  \n",
      "8            0.00        0        0         0      0        1         0  \n",
      "9        40348.79        0        0         0      1        0         0  \n",
      "               step        amount  oldbalanceOrg  newbalanceOrig  \\\n",
      "count  6.362620e+06  6.362620e+06   6.362620e+06    6.362620e+06   \n",
      "mean   2.433972e+02  1.798619e+05   8.338831e+05    8.551137e+05   \n",
      "std    1.423320e+02  6.038582e+05   2.888243e+06    2.924049e+06   \n",
      "min    1.000000e+00  0.000000e+00   0.000000e+00    0.000000e+00   \n",
      "25%    1.560000e+02  1.338957e+04   0.000000e+00    0.000000e+00   \n",
      "50%    2.390000e+02  7.487194e+04   1.420800e+04    0.000000e+00   \n",
      "75%    3.350000e+02  2.087215e+05   1.073152e+05    1.442584e+05   \n",
      "max    7.430000e+02  9.244552e+07   5.958504e+07    4.958504e+07   \n",
      "\n",
      "       oldbalanceDest  newbalanceDest       isFraud       CASH_IN  \\\n",
      "count    6.362620e+06    6.362620e+06  6.362620e+06  6.362620e+06   \n",
      "mean     1.100702e+06    1.224996e+06  1.290820e-03  2.199226e-01   \n",
      "std      3.399180e+06    3.674129e+06  3.590480e-02  4.141940e-01   \n",
      "min      0.000000e+00    0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%      0.000000e+00    0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "50%      1.327057e+05    2.146614e+05  0.000000e+00  0.000000e+00   \n",
      "75%      9.430367e+05    1.111909e+06  0.000000e+00  0.000000e+00   \n",
      "max      3.560159e+08    3.561793e+08  1.000000e+00  1.000000e+00   \n",
      "\n",
      "           CASH_OUT         DEBIT       PAYMENT      TRANSFER  \n",
      "count  6.362620e+06  6.362620e+06  6.362620e+06  6.362620e+06  \n",
      "mean   3.516633e-01  6.511783e-03  3.381461e-01  8.375622e-02  \n",
      "std    4.774895e-01  8.043246e-02  4.730786e-01  2.770219e-01  \n",
      "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
      "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
      "50%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
      "75%    1.000000e+00  0.000000e+00  1.000000e+00  0.000000e+00  \n",
      "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  \n"
     ]
    }
   ],
   "source": [
    "# importing data science libraries\n",
    "import pandas as pd\n",
    "\n",
    "fraud_dataset = pd.read_csv('../data/nonames.csv')\n",
    "print(\"There are \", len(fraud_dataset), \" samples\")\n",
    "print(fraud_dataset.shape)\n",
    "print(fraud_dataset.head(10))\n",
    "print(fraud_dataset.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (5090096, 12)\n",
      "X_train:  (5090096, 11)\n",
      "X_train:  (4072076, 11)\n",
      "X_val:  (1018020, 11)\n",
      "X_test:  (1272524, 12)\n",
      "X_test:  (1272524, 11)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = train_test_split(fraud_dataset, test_size=0.2, random_state=RANDOM_SEED)\n",
    "print(\"X_train: \", X_train.shape)\n",
    "# y_train = X_train[\"isFraud\"].copy(deep=True)\n",
    "X_train.pop(\"isFraud\")\n",
    "print(\"X_train: \", X_train.shape)\n",
    "X_train, X_val = train_test_split(X_train, test_size=0.2, random_state=RANDOM_SEED)\n",
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"X_val: \", X_val.shape)\n",
    "print(\"X_test: \", X_test.shape)\n",
    "y_test = X_test[\"isFraud\"].copy(deep=True)\n",
    "X_test.pop(\"isFraud\")\n",
    "print(\"X_test: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1]\n",
    "\n",
    "hidden_layer = [10, 8, 4]\n",
    "input_layer = Input(shape=(input_shape,))\n",
    "encoder1 = Dense(hidden_layer[0], activation=\"softmax\")(input_layer)\n",
    "encoder2 = Dense(hidden_layer[1], activation=\"softmax\")(encoder1)\n",
    "encoder3 = Dense(hidden_layer[2], activation=\"softmax\")(encoder2)\n",
    "decoder1 = Dense(hidden_layer[2], activation=\"softmax\")(encoder3)\n",
    "decoder2 = Dense(hidden_layer[1], activation=\"softmax\")(decoder1)\n",
    "decoder3 = Dense(input_shape, activation=\"softmax\")(decoder2)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 11)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                120       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 11)                99        \n",
      "=================================================================\n",
      "Total params: 403\n",
      "Trainable params: 403\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4072076 samples, validate on 1018020 samples\n",
      "Epoch 1/200\n",
      "4072076/4072076 [==============================] - 23s 6us/step - loss: 1074972479081.5903 - acc: 0.5876 - val_loss: 45597213088.5526 - val_acc: 0.6759\n",
      "Epoch 2/200\n",
      "4072076/4072076 [==============================] - 22s 5us/step - loss: 39841412444.0861 - acc: 0.7925 - val_loss: 37548051843.9053 - val_acc: 0.7912\n",
      "Epoch 3/200\n",
      "4072076/4072076 [==============================] - 22s 5us/step - loss: 37278299802.1287 - acc: 0.7476 - val_loss: 37275732397.6290 - val_acc: 0.7134\n",
      "Epoch 4/200\n",
      "4072076/4072076 [==============================] - 22s 6us/step - loss: 37119754922.8967 - acc: 0.6947 - val_loss: 37257892249.7529 - val_acc: 0.6992\n",
      "Epoch 5/200\n",
      "4072076/4072076 [==============================] - 22s 5us/step - loss: 37151848854.9902 - acc: 0.8024 - val_loss: 37331357235.7120 - val_acc: 0.8134\n",
      "Epoch 6/200\n",
      "4072076/4072076 [==============================] - 23s 6us/step - loss: 37055934749.9683 - acc: 0.8378 - val_loss: 37240511209.0107 - val_acc: 0.7906\n",
      "Epoch 7/200\n",
      "4072076/4072076 [==============================] - 22s 6us/step - loss: 36982573088.4224 - acc: 0.8392 - val_loss: 37206681696.9059 - val_acc: 0.8497\n",
      "Epoch 8/200\n",
      "4072076/4072076 [==============================] - 23s 6us/step - loss: 37015184752.2620 - acc: 0.8131 - val_loss: 37058784211.6611 - val_acc: 0.8472\n",
      "Epoch 9/200\n",
      "4072076/4072076 [==============================] - 22s 5us/step - loss: 36947717012.1732 - acc: 0.8402 - val_loss: 37022926780.0431 - val_acc: 0.8560\n",
      "Epoch 10/200\n",
      "4072076/4072076 [==============================] - 22s 6us/step - loss: 36989133121.6859 - acc: 0.7910 - val_loss: 37000161604.7364 - val_acc: 0.7826\n",
      "Epoch 11/200\n",
      "4072076/4072076 [==============================] - 22s 6us/step - loss: 36657372186.4203 - acc: 0.7844 - val_loss: 32587742420.8430 - val_acc: 0.7661\n",
      "Epoch 12/200\n",
      "4072076/4072076 [==============================] - 22s 6us/step - loss: 30808586905.4960 - acc: 0.7567 - val_loss: 30488769906.1215 - val_acc: 0.7650\n",
      "Epoch 13/200\n",
      "4072076/4072076 [==============================] - 22s 5us/step - loss: 29906252935.3991 - acc: 0.7700 - val_loss: 30652689414.1157 - val_acc: 0.7902\n",
      "Epoch 14/200\n",
      "4072076/4072076 [==============================] - 22s 6us/step - loss: 29671297261.0315 - acc: 0.7736 - val_loss: 32744347111.3863 - val_acc: 0.7180\n",
      "Epoch 15/200\n",
      "4072076/4072076 [==============================] - 23s 6us/step - loss: 24280674818.1762 - acc: 0.7566 - val_loss: 6082698156.3264 - val_acc: 0.7644\n",
      "Epoch 16/200\n",
      "4072076/4072076 [==============================] - 22s 5us/step - loss: 6247932740.9492 - acc: 0.7442 - val_loss: 8835039360.9832 - val_acc: 0.5398\n",
      "Epoch 17/200\n",
      "4072076/4072076 [==============================] - 22s 6us/step - loss: 5324884493.7978 - acc: 0.7472 - val_loss: 4099637113.6152 - val_acc: 0.8098\n",
      "Epoch 18/200\n",
      "4072076/4072076 [==============================] - 22s 5us/step - loss: 2957072261.3475 - acc: 0.8325 - val_loss: 2127536120.5138 - val_acc: 0.8651\n",
      "Epoch 19/200\n",
      "4072076/4072076 [==============================] - 22s 5us/step - loss: 2339125357.9491 - acc: 0.8725 - val_loss: 2041045284.5510 - val_acc: 0.8760\n",
      "Epoch 20/200\n",
      "4072076/4072076 [==============================] - 22s 6us/step - loss: 2189827224.1166 - acc: 0.8627 - val_loss: 2004653971.5555 - val_acc: 0.9084\n",
      "Epoch 21/200\n",
      "3242000/4072076 [======================>.......] - ETA: 4s - loss: 2135334191.4176 - acc: 0.8859"
     ]
    }
   ],
   "source": [
    "nb_epoch = 200\n",
    "batch_size = 1000\n",
    "# using mean squared error\n",
    "autoencoder.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath=\"../saved/basicAE3.h5\",\n",
    "                               verbose=0,\n",
    "                               save_best_only=True)\n",
    "tensorboard = TensorBoard(log_dir='./logs',\n",
    "                          histogram_freq=0,\n",
    "                          write_graph=True,\n",
    "                          write_images=True)\n",
    "history = autoencoder.fit(X_train, X_train,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(X_val, X_val),\n",
    "                    verbose=1,\n",
    "                    callbacks=[checkpointer, tensorboard]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing visualization tools\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "\n",
    "autoencoder = load_model('../saved/basicAE3.h5')\n",
    "\n",
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "predictions = autoencoder.predict(X_test)\n",
    "# calculate my own MSE\n",
    "mse = np.mean(np.power(X_test - predictions, 2), axis=1)\n",
    "error_df = pd.DataFrame({'reconstruction_error': mse, 'true_class': y_test})\n",
    "error_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
